# program.py

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from datetime import timedelta, date

# --- C·∫•u h√¨nh trang Streamlit ---
st.set_page_config(layout="wide", page_title="D·ª± ƒêo√°n Gi√° Bitcoin", page_icon="‚Çø")

# --- C√°c h√†m x·ª≠ l√Ω d·ªØ li·ªáu v√† m√¥ h√¨nh (Gi·ªØ nguy√™n nh∆∞ c≈©) ---
@st.cache_data
def load_and_preprocess_data(file_path='Bitcoin.csv'):
    try:
        df = pd.read_csv(file_path, delimiter=';')
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {file_path}. Vui l√≤ng ƒë·∫£m b·∫£o file n·∫±m trong c√πng th∆∞ m·ª•c.")
        return None, None, None, None, None

    try:
        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)
    except Exception as e:
        st.error(f"L·ªói khi chuy·ªÉn ƒë·ªïi c·ªôt 'Date': {e}. Ki·ªÉm tra ƒë·ªãnh d·∫°ng ng√†y trong file CSV.")
        return None, None, None, None, None
        
    df.sort_values('Date', inplace=True)
    df.set_index('Date', inplace=True)

    if 'Close' not in df.columns or 'Open' not in df.columns:
        st.error("File CSV thi·∫øu c·ªôt 'Close' ho·∫∑c 'Open'.")
        return None, None, None, None, None

    df_processed = df[['Close', 'Open']].copy()
    for col in ['Close', 'Open']:
        if df_processed[col].dtype == 'object':
            try:
                df_processed[col] = df_processed[col].str.replace(',', '.', regex=False).astype(float)
            except Exception as e:
                st.error(f"L·ªói khi chuy·ªÉn ƒë·ªïi c·ªôt '{col}' sang s·ªë: {e}. Ki·ªÉm tra d·ªØ li·ªáu trong c·ªôt.")
                return None, None, None, None, None

    df_processed.fillna(method='ffill', inplace=True)
    df_processed.fillna(method='bfill', inplace=True)

    if df_processed.isnull().values.any():
        st.error("D·ªØ li·ªáu v·∫´n c√≤n gi√° tr·ªã NaN sau khi fill. Ki·ªÉm tra l·∫°i file CSV.")
        return None, None, None, None, None

    target_col = 'Close'
    lags_list = [1, 3, 7, 14, 30]
    rolling_windows_list = [7, 30]

    for lag_val in lags_list:
        df_processed[f'Close_Lag_{lag_val}'] = df_processed[target_col].shift(lag_val)
    for window_val in rolling_windows_list:
        df_processed[f'Close_Rolling_Mean_{window_val}'] = df_processed[target_col].rolling(window=window_val, min_periods=1).mean().shift(1)
    for lag_val in lags_list:
        df_processed[f'Open_Lag_{lag_val}'] = df_processed['Open'].shift(lag_val)
    for window_val in rolling_windows_list:
        df_processed[f'Open_Rolling_Mean_{window_val}'] = df_processed['Open'].rolling(window=window_val, min_periods=1).mean().shift(1)

    df_processed.dropna(inplace=True)

    if df_processed.empty:
        st.error("Kh√¥ng c√≤n d·ªØ li·ªáu sau khi t·∫°o ƒë·∫∑c tr∆∞ng v√† lo·∫°i b·ªè NaN. C√≥ th·ªÉ do file CSV qu√° √≠t d√≤ng.")
        return None, None, None, None, None

    feature_names_list = [f'Close_Lag_{lag_val}' for lag_val in lags_list] + \
                         [f'Close_Rolling_Mean_{window_val}' for window_val in rolling_windows_list] + \
                         [f'Open_Lag_{lag_val}' for lag_val in lags_list] + \
                         [f'Open_Rolling_Mean_{window_val}' for window_val in rolling_windows_list]
    
    return df_processed, feature_names_list, lags_list, rolling_windows_list, target_col

@st.cache_resource
def train_model(_df_processed, _feature_names, _target_col):
    if _df_processed is None or not _feature_names or _target_col not in _df_processed.columns:
        return None, None, None, None, None, None, None

    X = _df_processed[_feature_names]
    y = _df_processed[_target_col]

    if X.empty or y.empty:
        return None, None, None, None, None, None, None

    split_ratio = 0.8
    split_index = int(len(X) * split_ratio)
    X_train_orig, y_train = X.iloc[:split_index], y.iloc[:split_index]
    X_test_orig, y_test = X.iloc[split_index:], y.iloc[split_index:]

    if len(X_train_orig) == 0:
        return None, None, None, None, None, None, None

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_orig)
    
    alpha_value = 0.1
    model = Lasso(alpha=alpha_value, max_iter=10000)
    model.fit(X_train_scaled, y_train)
    
    y_pred_test_plot = None
    if not X_test_orig.empty:
        X_test_scaled_for_plot = scaler.transform(X_test_orig)
        y_pred_test_plot = model.predict(X_test_scaled_for_plot)

    return model, scaler, X_train_orig, y_train, X_test_orig, y_test, y_pred_test_plot

def predict_for_future_date(target_date_dt, model, scaler, historical_data_full, 
                            feature_names_list, lags_list, rolling_windows_list, target_col_name='Close'):
    last_known_date_dt = historical_data_full.index[-1]
    current_data_df = historical_data_full[[target_col_name, 'Open']].copy()
    features_for_target_prediction_unscaled_df = None 

    num_days_to_predict = (target_date_dt - last_known_date_dt).days

    if num_days_to_predict <= 0: 
        if target_date_dt in historical_data_full.index:
            actual_val = historical_data_full.loc[target_date_dt, target_col_name]
            if all(f in historical_data_full.columns for f in feature_names_list):
                 features_for_target_prediction_unscaled_df = historical_data_full.loc[[target_date_dt], feature_names_list]
            return actual_val, current_data_df, features_for_target_prediction_unscaled_df
        else:
            return None, current_data_df, None 

    for i in range(num_days_to_predict):
        current_prediction_date_dt = last_known_date_dt + timedelta(days=i + 1)
        next_day_feature_values = {}

        for lag_val in lags_list:
            next_day_feature_values[f'Close_Lag_{lag_val}'] = current_data_df[target_col_name].iloc[-lag_val]
        for window_val in rolling_windows_list:
            next_day_feature_values[f'Close_Rolling_Mean_{window_val}'] = current_data_df[target_col_name].iloc[-window_val:].mean()
        for lag_val in lags_list:
            next_day_feature_values[f'Open_Lag_{lag_val}'] = current_data_df['Open'].iloc[-lag_val]
        for window_val in rolling_windows_list:
            next_day_feature_values[f'Open_Rolling_Mean_{window_val}'] = current_data_df['Open'].iloc[-window_val:].mean()

        next_day_features_df_orig = pd.DataFrame([next_day_feature_values], columns=feature_names_list, index=[current_prediction_date_dt])
        next_day_features_scaled = scaler.transform(next_day_features_df_orig)
        prediction = model.predict(next_day_features_scaled)[0]

        new_row = pd.DataFrame({target_col_name: [prediction], 'Open': [prediction]}, index=[current_prediction_date_dt])
        current_data_df = pd.concat([current_data_df, new_row])
        
        if current_prediction_date_dt == target_date_dt:
            features_for_target_prediction_unscaled_df = next_day_features_df_orig

    if target_date_dt in current_data_df.index:
        return current_data_df.loc[target_date_dt, target_col_name], current_data_df, features_for_target_prediction_unscaled_df
    return None, current_data_df, None

# --- B·∫Øt ƒë·∫ßu Giao di·ªán Streamlit ---
st.title("‚Çø B·∫£ng ƒêi·ªÅu Khi·ªÉn D·ª± ƒêo√°n Gi√° Bitcoin")
st.markdown("M·ªôt ·ª©ng d·ª•ng web s·ª≠ d·ª•ng m√¥ h√¨nh **Lasso Regression** ƒë·ªÉ d·ª± b√°o gi√° ƒë√≥ng c·ª≠a c·ªßa Bitcoin trong t∆∞∆°ng lai.")

# --- T·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu ---
df_processed, feature_names, lags, rolling_windows, target_col = load_and_preprocess_data()

if df_processed is None:
    st.error("Kh√¥ng th·ªÉ t·∫£i ho·∫∑c x·ª≠ l√Ω d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra file 'Bitcoin.csv' v√† ƒë·ªãnh d·∫°ng c·ªßa n√≥.")
    st.stop()

# --- Hu·∫•n luy·ªán m√¥ h√¨nh ---
model, scaler, X_train_orig, y_train, X_test_orig, y_test, y_pred_test_plot = train_model(df_processed, feature_names, target_col)

if model is None:
    st.error("Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh. Ki·ªÉm tra l·∫°i d·ªØ li·ªáu v√† c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω.")
    st.stop()

# --- B·ªë c·ª•c giao di·ªán v·ªõi Tabs ---
tab1, tab2, tab3 = st.tabs(["üìà B·∫£ng ƒëi·ªÅu khi·ªÉn & D·ª± ƒëo√°n", "üî¨ Ph√¢n t√≠ch M√¥ h√¨nh", "üóÉÔ∏è Xem D·ªØ li·ªáu"])

# ==============================================================================
# --- TAB 1: B·∫¢NG ƒêI·ªÄU KHI·ªÇN & D·ª∞ ƒêO√ÅN ---
# ==============================================================================
with tab1:
    col1, col2 = st.columns([1, 3]) # C·ªôt input nh·ªè h∆°n, c·ªôt output l·ªõn h∆°n

    # --- C·ªôt 1: Input c·ªßa ng∆∞·ªùi d√πng ---
    with col1:
        st.subheader("‚öôÔ∏è T√πy ch·ªçn D·ª± ƒëo√°n")
        
        last_date_in_data_dt = df_processed.index[-1].date()
        default_prediction_date = last_date_in_data_dt + timedelta(days=7)
        
        selected_date = st.date_input(
            "Ch·ªçn ng√†y mu·ªën d·ª± ƒëo√°n:",
            value=default_prediction_date,
            min_value=df_processed.index.min().date(),
            help="Ch·ªçn m·ªôt ng√†y trong t∆∞∆°ng lai ƒë·ªÉ m√¥ h√¨nh d·ª± ƒëo√°n gi√°."
        )
        selected_date_dt = pd.to_datetime(selected_date)

        days_to_show = st.slider(
            "S·ªë ng√†y l·ªãch s·ª≠ hi·ªÉn th·ªã tr√™n bi·ªÉu ƒë·ªì:",
            min_value=90,
            max_value=len(df_processed),
            value=365,
            step=30,
            help="K√©o ƒë·ªÉ thay ƒë·ªïi kho·∫£ng th·ªùi gian l·ªãch s·ª≠ ƒë∆∞·ª£c v·∫Ω tr√™n bi·ªÉu ƒë·ªì."
        )

        if st.button("üöÄ Ch·∫°y D·ª± ƒêo√°n", type="primary", use_container_width=True):
            st.session_state.run_prediction = True
            st.session_state.selected_date_dt = selected_date_dt
            st.session_state.days_to_show = days_to_show
        
        st.markdown("---")
        st.info(f"D·ªØ li·ªáu ƒë∆∞·ª£c c·∫≠p nh·∫≠t l·∫ßn cu·ªëi v√†o: **{last_date_in_data_dt.strftime('%d-%m-%Y')}**")

    # --- C·ªôt 2: Hi·ªÉn th·ªã k·∫øt qu·∫£ ---
    with col2:
        st.subheader("üìä K·∫øt qu·∫£ & Bi·ªÉu ƒë·ªì")
        
        # Placeholder cho k·∫øt qu·∫£
        result_placeholder = st.empty()

        # Logic hi·ªÉn th·ªã k·∫øt qu·∫£
        if 'run_prediction' in st.session_state and st.session_state.run_prediction:
            with st.spinner("ƒêang t√≠nh to√°n d·ª± ƒëo√°n..."):
                predicted_price, extended_data, features_df = predict_for_future_date(
                    st.session_state.selected_date_dt, model, scaler, df_processed,
                    feature_names, lags, rolling_windows, target_col
                )

            if predicted_price is not None:
                # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë
                metric_cols = st.columns(3)
                metric_cols[0].metric(
                    label=f"Gi√° d·ª± ƒëo√°n ng√†y {st.session_state.selected_date_dt.strftime('%d-%m-%Y')}",
                    value=f"${predicted_price:,.2f}"
                )
                
                # So s√°nh v·ªõi ng√†y tr∆∞·ªõc ƒë√≥
                previous_day_price = df_processed[target_col].iloc[-1]
                delta = predicted_price - previous_day_price
                metric_cols[1].metric(
                    label=f"So v·ªõi ng√†y cu·ªëi c√πng ({last_date_in_data_dt.strftime('%d-%m-%Y')})",
                    value=f"${previous_day_price:,.2f}",
                    delta=f"${delta:,.2f}"
                )

                # Bi·ªÉu ƒë·ªì
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ v·∫Ω
                history_to_plot = df_processed.tail(st.session_state.days_to_show)
                ax.plot(history_to_plot.index, history_to_plot[target_col], label='Gi√° L·ªãch S·ª≠', color='dodgerblue', lw=2)

                # V·∫Ω ph·∫ßn d·ª± ƒëo√°n trong t∆∞∆°ng lai
                # S·ª≠a d√≤ng 256
                if st.session_state.selected_date_dt.date() > last_date_in_data_dt:
    # L·∫•y ra ph·∫ßn d·ªØ li·ªáu d·ª± ƒëo√°n trong t∆∞∆°ng lai t·ª´ `extended_data`
    # ƒêi·ªÅu ki·ªán so s√°nh ·ªü ƒë√¢y c≈©ng c·∫ßn nh·∫•t qu√°n
                    forecast_period = extended_data[extended_data.index.date > last_date_in_data_dt]
                    if not forecast_period.empty:
                        ax.plot(forecast_period.index, forecast_period[target_col], label='ƒê∆∞·ªùng D·ª± ƒêo√°n', color='darkorange', linestyle='--', marker='o', markersize=4)
                # ƒê√°nh d·∫•u ƒëi·ªÉm d·ª± ƒëo√°n
                ax.scatter([st.session_state.selected_date_dt], [predicted_price], color='red', s=100, zorder=5, label=f'ƒêi·ªÉm D·ª± ƒêo√°n')
                
                ax.set_title(f"L·ªãch s·ª≠ gi√° v√† D·ª± ƒëo√°n cho ng√†y {st.session_state.selected_date_dt.strftime('%d-%m-%Y')}", fontsize=14)
                ax.set_ylabel("Gi√° ƒê√≥ng C·ª≠a (USD)", fontsize=10)
                ax.grid(True, linestyle='--', alpha=0.6)
                ax.legend()
                plt.tight_layout()
                st.pyplot(fig)

                # Hi·ªÉn th·ªã c√°c ƒë·∫∑c tr∆∞ng trong expander
                with st.expander("Xem c√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho d·ª± ƒëo√°n"):
                    if features_df is not None and not features_df.empty:
                        st.dataframe(features_df.T.rename(columns={features_df.index[0]: "Gi√° tr·ªã"}).style.format("{:,.2f}"))
                    else:
                        st.warning("Kh√¥ng c√≥ th√¥ng tin ƒë·∫∑c tr∆∞ng cho ng√†y n√†y.")

            else:
                st.error("Kh√¥ng th·ªÉ th·ª±c hi·ªán d·ª± ƒëo√°n. Vui l√≤ng th·ª≠ l·∫°i.")
        else:
            result_placeholder.info("H√£y ch·ªçn ng√†y v√† nh·∫•n n√∫t 'Ch·∫°y D·ª± ƒêo√°n' ƒë·ªÉ xem k·∫øt qu·∫£.")


# ==============================================================================
# --- TAB 2: PH√ÇN T√çCH M√î H√åNH ---
# ==============================================================================
with tab2:
    st.header("üî¨ Ph√¢n t√≠ch M√¥ h√¨nh Lasso Regression")
    
    st.subheader("1. Hi·ªáu su·∫•t M√¥ h√¨nh tr√™n T·∫≠p D·ªØ li·ªáu Ki·ªÉm tra (Test Set)")
    st.markdown("Bi·ªÉu ƒë·ªì d∆∞·ªõi ƒë√¢y so s√°nh gi√° th·ª±c t·∫ø (m√†u xanh) v√† gi√° m√¥ h√¨nh d·ª± ƒëo√°n (m√†u cam) tr√™n 20% d·ªØ li·ªáu cu·ªëi c√πng (t·∫≠p test) ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh.")
    
    fig_test, ax_test = plt.subplots(figsize=(12, 6))
    ax_test.plot(y_test.index, y_test, label='Gi√° Th·ª±c T·∫ø (Actual)', color='dodgerblue')
    ax_test.plot(y_test.index, y_pred_test_plot, label='Gi√° D·ª± ƒêo√°n (Predicted)', color='darkorange', linestyle='--')
    ax_test.set_title("So s√°nh Gi√° Th·ª±c T·∫ø v√† D·ª± ƒêo√°n tr√™n T·∫≠p Test", fontsize=14)
    ax_test.set_ylabel("Gi√° ƒê√≥ng C·ª≠a (USD)", fontsize=10)
    ax_test.legend()
    ax_test.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    st.pyplot(fig_test)

    st.subheader("2. M·ª©c ƒë·ªô Quan tr·ªçng c·ªßa c√°c ƒê·∫∑c tr∆∞ng (Feature Importances)")
    st.markdown("M√¥ h√¨nh Lasso g√°n m·ªôt 'h·ªá s·ªë' (coefficient) cho m·ªói ƒë·∫∑c tr∆∞ng. H·ªá s·ªë c√†ng l·ªõn (c·∫£ √¢m v√† d∆∞∆°ng) cho th·∫•y ƒë·∫∑c tr∆∞ng ƒë√≥ c√†ng c√≥ ·∫£nh h∆∞·ªüng l·ªõn ƒë·∫øn k·∫øt qu·∫£ d·ª± ƒëo√°n.")

    # L·∫•y h·ªá s·ªë v√† t·∫°o DataFrame
    coefficients = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': model.coef_
    }).sort_values(by='Coefficient', key=abs, ascending=False)
    
    # V·∫Ω bi·ªÉu ƒë·ªì c·ªôt
    fig_coef, ax_coef = plt.subplots(figsize=(10, 8))
    ax_coef.barh(coefficients['Feature'], coefficients['Coefficient'], color='skyblue')
    ax_coef.invert_yaxis() # Hi·ªÉn th·ªã ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t ·ªü tr√™n c√πng
    ax_coef.set_title("H·ªá s·ªë c·ªßa c√°c ƒê·∫∑c tr∆∞ng trong M√¥ h√¨nh Lasso", fontsize=14)
    ax_coef.set_xlabel("Gi√° tr·ªã H·ªá s·ªë (Coefficient)", fontsize=10)
    plt.tight_layout()
    st.pyplot(fig_coef)


# ==============================================================================
# --- TAB 3: XEM D·ªÆ LI·ªÜU ---
# ==============================================================================
with tab3:
    st.header("üóÉÔ∏è D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c X·ª≠ l√Ω")
    st.markdown("ƒê√¢y l√† b·∫£ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch, t·∫°o ƒë·∫∑c tr∆∞ng v√† s·∫µn s√†ng ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh.")
    
    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang CSV ƒë·ªÉ t·∫£i xu·ªëng
    @st.cache_data
    def convert_df_to_csv(df):
        return df.to_csv().encode('utf-8')

    csv_data = convert_df_to_csv(df_processed)

    st.download_button(
        label="üì• T·∫£i D·ªØ li·ªáu (CSV)",
        data=csv_data,
        file_name='processed_bitcoin_data.csv',
        mime='text/csv',
    )
    
    st.dataframe(df_processed)